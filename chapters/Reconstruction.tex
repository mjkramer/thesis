\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Event reconstruction}
\label{chap:recon}

\section{Introduction}
\label{sec:reconIntro}

\autoref{chap:calib} discussed the process of taking the raw ADC and TDC values of PMT hits, as measured by the front-end electronics, and converting those values, channel-by-channel, into the more useful quantities of hit charge (in photoelectrons) and hit time (in, e.g., nanoseconds). The next step is to combine information from all of the channels in order to derive properties of the event as a whole, such as the amount of deposited energy and the approximate location of the vertex. This is the purpose of \emph{reconstruction.}

Reconstruction begins with the calculation of the total observed charge (i.e. photoelectron count) by summing hits across all channels, with a correction for the presence of any inactive channels. This \emph{nominal charge} is then converted into \emph{raw energy}, in MeV, according to an energy scale determined using regular (weekly or more) calibrations. At the same time, the distribution of charge across PMTs is used to estimate the location within the AD of the event. The position is then used to apply a \emph{nonuniformity} adjustment to the raw energy, to correct for the position-dependent response of the detector. This gives the \emph{reconstructed energy}, which is used in most subsequent analysis stages. The details of the energy reconstruction (as illustrated by the flow chart in \autoref{fig:pmt2etrue}) are discussed in \autoref{sec:reconEnergy}.

The reconstructed energy should not be regarded as the best estimate of the true energy deposited by the event, given the complexities involved in the nonlinearity of the scintillator and its varying responses to different particle types. Rather, reconstructed energy should be considered a \emph{position-corrected measure of the total observed amount of light}, and hence should be regarded as proportional to the total amount of light produced in the scintillator. Due to the calibration methods used, reconstructed energy \emph{does} agree (by construction) with deposited energy for the 8~MeV gamma-ray cascade from nGd capture, but this is only a special case.

In parallel with the energy reconstruction, vertex reconstruction is carried out using the spatial distribution of recorded photoelectrons. This process is illustrated by the flow chart in \autoref{fig:vtx_rec_flow} and detailed in \autoref{chap:reconVertex}. Although the reconstructed vertex has historically not been \emph{directly} used in the n-Gd oscillation analysis (e.g., in the selection of IBD candidates), vertex information plays an important role in the estimation of certain correlated backgrounds, particularly the so-called AmC background (\autoref{sec:bkgAmC}), as well as in alternative oscillation analyses using neutron capture on hydrogen \cite{new_nH_paper}. In \autoref{sec:cutVaryVertexCut}, we explore the effects of including a vertex requirement in our IBD selection, demonstrating that our analysis is robust against such modifications.

Daya Bay has developed multiple independent reconstruction algorithms. The two that have been widely used in published results are known as AdSimple and AdScaled. They differ primarily in their calibration procedures, their vertex reconstruction algorithms, and their methods of correcting for nonuniformity. Both give consistent results in the oscillation analysis, and both will be detailed in this chapter, but only AdSimple will be used in our analysis.

\section{Energy reconstruction}
\label{sec:reconEnergy}

The energy reconstruction begins with the total measured charge, and proceeds through a series of corrections to produce a best estimate of the true deposited energy, as illustrated in \autoref{fig:pmt2etrue}. In the sections that follow, we will be repeatedly referring to various estimated energies:
\begin{itemize}
\item $\mathbf{E_{raw}}$\textbf{:} The \emph{raw} energy, i.e., the total measured charge from the PMTs, divided by the energy scale.
\item $\mathbf{E_{cor}}$\textbf{:} The \emph{corrected} energy, calculated from $E_{\mathrm{raw}}$ by applying a \emph{time-independent} correction for the geometric nonuniformity of the AD's response (\autoref{sec:reconEnergyNU}).
\item $\mathbf{E_{rec}}$\textbf{:} The final \emph{reconstructed energy}, obtained from $E_{\mathrm{cor}}$ by applying an additional correction for the time-dependence of the geometric nonuniformity\footnote{Caused by, e.g., the gradual increase in the attenuation length of the scintillator.} This is stored as the output of the AdSimple reconstruction. Two events which occur at different positions/times, but which are othewise identical, will produce the same $E_{\mathrm{rec}}$. The energy scale is defined such that $E_{\mathrm{rec}} = \SI{7.94}{MeV}$ for spallation neutrons.
\item $\mathbf{E_{vis}}$\textbf{:} The \emph{visible} energy, obtained from $E_{\mathrm{rec}}$ by applying a correction for the nonlinearity of the electronics (i.e., correcting the charge such that it is directly proportional to the number of photoelectrons). In physical terms, $E_{\mathrm{vis}}$ is proportional to the number of photons produced in the scintillator.\footnote{In practice, $E_{\mathrm{rec}}$ is converted into $E_{\mathrm{dep}}$ in a single step using the combined (scintillator + electronics) nonlinearity model described in \autoref{sec:reconEnergyNL}. Hence, $E_{\mathrm{vis}}$ never explicitly appears.}
\item $\mathbf{E_{dep}}$\textbf{:} The \emph{deposited} energy, obtained from $E_{\mathrm{vis}}$ by correcting for the (particle-dependent) nonlinearity of the scintillator. This is the final estimate of the actual energy physically deposited.
\item $\mathbf{E_{\nu}}$\textbf{:} The \emph{neutrino} energy, calculated from $E_{\mathrm{dep}}$ based on the kinematics of the IBD interaction.
\end{itemize}

\begin{figure}[h]
  \includegraphics[scale=1.0]{Reconstruction/pmt2etrue_flow.pdf}
  \caption{Conceptual flowchart of the AdSimple energy reconstruction process. In practice, the electronics and scintillator nonlinearity corrections are applied in a single step, using the correction function described in \cite{NonlinearityPaper}. An alternative reconstruction, known as AdSimpleNL, corrects for the electronics nonlinearity at the level of individual channels, prior to summing of the charges to obtain the nonlinearity-corrected nominal charge (``NominalChargeNL''). Both methods produce consistent results. Here, we use the more ``traditional'' AdSimple algorithm.}
  \label{fig:pmt2etrue}
\end{figure}

\subsection{Event charge determination}
\label{sec:reconEnergyCharge}

\subsubsection{Hit selection}
\label{sec:reconHitSelection}

The first step in the energy reconstruction is to estimate the total \emph{charge}, i.e., number of photoelectrons, observed from the underlying interaction. Here, the main consideration is the choice of hits to include in the sum. Based on the design of the trigger electronics, a trigger will be issued about \SI{1550 \pm 50}{ns} after the accumulation of a sufficient number of hits and/or total charge. Including an additional spread of 50~ns to account for the time-of-flight of the photons, one would infer that a window of around [-1650, -1450]~ns would be reasonable.\footnote{Here, as in previous discussions, the origin of time ($t = 0$) is the instant at which the trigger is issued. Since all of the recorded hits occur prior to the trigger, their time values are negative.} In practice, Daya Bay actually uses a window of [-1650, -1250]~ns. The justification for this wider window is related to the properties of the liquid scintillator itself.

When an interaction deposits energy in the LS, various molecular excited states decay stochastically, emitting light in the process. In the Daya Bay LS, the light emission can be accurately modeled with three components: a fast one ($\sim$5~ns time constant), a medium one ($\sim$30~ns), and a slow one ($\sim$150~ns). The time for light to propagate, directly or via reflections, adds a position-dependent delay of a few dozen ns. Altogether, 5\% of the PMT hits occur some 50-150~ns after the primary peak \cite{peakCharge}. In order to include this ``late'' light, and thereby hopefully improve the energy resolution, Daya Bay uses the widened hit selection window of [-1650, -1250]~ns.

With a window defined for hit selection, the next question is which hits to use from inside this window. Based on the measures discussed in \autoref{sec:calibHitCharge} for correcting the biases in closely-spaced hits, in principle every hit should be trustworthy. In practice, hits that arrive within 100~ns of each other will produce a single shaped peak, and hence only the first hit will have a nonzero calibrated charge. Since most primary light hits \emph{do} in fact arrive within 100~ns of each other, there is usually no difference between taking all hits and taking only the first hit. The \emph{default} or \emph{nominal} charge is accordingly defined as \emph{the sum across channels of the earliest hit in the time window of [-1650, -1250]~ns (relative to the trigger time).}

The nominal charge will generally account for all of the fast/medium light, but will omit \emph{some} of the slow light \emph{unless there is no fast/medium light seen by the channel}. As such, high-energy events will miss a greater proportion of slow light compared to low-energy events, since in the latter case there will be more channels seeing no fast/medium light. This introduces a degree of nonlinearity in the overall detector response. If, instead, one were to take \emph{all} hits in [-1650, -1250]~ns, instead of just the earliest hit, the sum would in principle accurately include all of the components, without the aforementioned nonlinearity. This does not appear to have ever been proposed; the reasons are unknown, but may be related to the fact that this method is more sensitive to the details of the corrections for closely-spaced hits.\footnote{%
As an alternative to the nominal charge, the \emph{peak charge} is defined as the sum across channels of the earliest hit in [-1650, -1480]~ns. This effectively excludes the late light, mitigating the associated nonlinearity found in the nominal charge. One downside is that slightly less light is included, but late light accounts for only 5\% of the total, and the nominal charge misses some of it anyway, so overall, only a couple percent of photons are lost compared to the nominal charge. In any case, it is possible to measure and correct for any nonlinearity inherent in the charge calculation, as discussed in \autoref{sec:reconEnergyNL}. We use the nominal charge, since that is what the nonlinearity has been measured against.%
}


\subsubsection{Active channel correction}
\label{sec:reconActiveChan}

At any given time, there may be dead or malfunctioning channels in an AD. As described in \autoref{sec:calibCQ}, these are recorded in the channel quality (CQ) database according to a number of criteria. If, at the time of a given trigger, a channel is marked as ``bad'', then its charge is \emph{not} included in the total nominal charge. This, naturally, will result in a downward bias on the total. In principle, the size of the effect depends on the position of the event: The effect is larger if the event is closer to the PMT, and vice versa. In practice, however, Daya Bay uses a simple, position-independent correction of $192/N$, where $N$ is the number of active channels. Given that the Daya Bay ADs almost always have fewer than two bad channels, this correction was found to reliably correct the bias, with negligible impact on the resolution.

\subsubsection{Summary}
\label{sec:reconChargeSummary}

In summary, the nominal charge is computed as follows: For every active channel, take the calibrated charge of the earliest hit in the pre-trigger window of [-1650, -1250]~ns. Sum these up, and then apply a correction of $192/N$, where $N$ is the number of active channels. In subsequent stages of the energy reconstruction, the nominal charge (in PE) is scaled by a time-dependent energy scale to give the \emph{raw energy} (in MeV), then adjusted by a time- and position-dependent nonuniformity correction to give the \emph{reconstructed energy} and, finally, at the highest levels of analysis, adjusted again to correct for electronics nonlinearity, scintillator nonlinearity, and IBD kinematics to give the \emph{true neutrino energy}. These steps are discussed below.

\subsection{Energy scale calibration}
\label{sec:reconEnergyScale}

The nominal charge produced by a given interaction can vary over time due to, for instance, degradation or contamination of the scintillator. Furthermore, for the purpose of physics analysis, we would prefer to speak of the energy (in, e.g., MeV) deposited in the scintillator, rather than the amount of light observed. Accordingly, the object of the energy scale calibration is to fix the definition of a ``visible'' MeV, and to ensure that any given event will yield the same reconstructed energy in every AD, regardless of changes over time in the behavior of the scintillator.

In what follows, repeated references will be made to the so-called \emph{Crystal Ball (CB) function} \cite{cbfunction}. This empirical function was initially developed by the Crystal Ball collaboration, which operated a neutral-particle detector (containing an inner spark chamber surrounded by a sphere of scintillating crystals) at SLAC around the early 1980s. The CB function is designed to model ``lossy'' processes, such as energy deposition in a detector where some energy can escape detection. At Daya Bay, neutron capture on gadolinium provide an example of such a process, as gamma rays may exit the scintillating volume before depositing all of their energy. To account for both fully and partially contained events, the CB function includes a Gaussian ``core'' and a power-law ``tail'', respectively:
\begin{equation}
  \label{eq:cbfunction}
  f(x;\alpha,n,\bar x,\sigma) = N \cdot \begin{cases} \exp(- \frac{(x - \bar x)^2}{2 \sigma^2}), & \mbox{for }\frac{x - \bar x}{\sigma} > -\alpha \\
    A \cdot (B - \frac{x - \bar x}{\sigma})^{-n}, & \mbox{for }\frac{x - \bar x}{\sigma} \leqslant -\alpha,\end{cases}
\end{equation}
where
\[
  A = \left(\frac{n}{\left| \alpha \right|}\right)^n \cdot \exp\left(- \frac {\left| \alpha \right|^2}{2}\right),%
  \qquad%
  B = \frac{n}{\left| \alpha \right|}  - \left| \alpha \right|,
\]
and $N$ is a normalization factor. In the case of fitting the energy spectrum of nGd captures, we will be discussing the use of a \emph{double Crystal Ball function}, that is, the sum of two CB functions, one of which fits the 7.937~MeV peak from capture on $^{157}$Gd, and the other of which fits the 8.536~MeV peak from $^{155}$Gd. Among the isotopes of Gd with significant neutron capture cross sections, these two are the most abundant in natural Gd.

Given that the response of the ADs (i.e. the nominal charge) depends on the type of interaction and is nonlinear with respect to the deposited energy, the energy scale (in charge per MeV) will depend on the choice of interaction used to calibrate the scale. Daya Bay's two main reconstruction algorithms, AdSimple and AdScaled, both define the energy scale such that a neutron capture on gadolinium will yield approximately 8 MeV\footnote{More precisely, the energy scale is defined such that the nGd capture spectrum contains two peaks (as fit by a double Crystal Ball function) at reconstructed energies of 7.937 and 8.536~MeV. In principle, the nonlinearity of the detector could mean that if the first peak is fixed at 7.94~MeV, the second might not lie exactly at 8.54~MeV, suggesting that the spacing between the two peaks should be allowed to float in the fit. In practice, however, at such high energies, the degree of nonlinearity (relative to the energy resolution) is insufficient to compromise the fit, and so a fixed peak spacing is used.}. However, there are significant differences between the methodology of the two calibrations.

For AdSimple, the calibration uses Gd captures of spallation neutrons produced by high-energy cosmic muons traversing the AD. Since this analysis is based on AdSimple, we give a detailed description of its calibration procedure in the section that follows. One of the advantages of using spallation neutrons is that they are distributed uniformly throughout the target volume, much like IBD neutrons. A disadvantage is that the ensuing energy scale is slightly biased (upward), relative to that of IBD neutrons, due to PMT afterpulsing resulting from the large amount of charge produced by the parent muon. In the end, however, this is accounted for in the nonlinearity model (\autoref{sec:reconEnergyNL}); as long as the energy scale calibration provides consistency in time, space, and between ADs, it is sufficient.

In comparison to AdSimple, AdScaled uses a significantly different method of calibrating the energy scale. We only discuss it briefly, since AdScaled is not used in this analysis. Essentially, the method is based on using weekly $^{60}$Co calibrations to monitor the time variation of the light yield, and occasional $\sim$40-hour AmC calibrations (which produce nGd captures) to measure the nonlinearity between the $^{60}$Co and nGd peaks. Every Friday, the $^{60}$Co source is deployed from ACU A to the center of each AD for 10 minutes. From this data, a histogram containing the total nominal charge of each event is extracted. In the vicinity of the $^{60}$Co peak, this histogram is fit to a Gaussian plus Crystal Ball function \cite{adScaledTechnote}. The nominal charge (at the peak of the fit function) is then multiplied by the ratio between the nGd and $^{60}$Co charge peaks\footnote{This ratio, which is relatively stable, is determined from runs in which the $^{60}$Co and $^{241}$Am-$^{13}$C sources are deployed together at the center of the AD. In the nominal charge spectrum from such a run, the $^{60}$Co peak is fit, as above, to a Gaussian plus Crystal Ball function. Meanwhile, the nGd peak is fit to a simple Gaussian function \cite{adScaledTechnote}; since the nGd captures occur at the detector's center, the gamma-ray leakage tail is very small, allowing the use of a Gaussian function instead of a (double) Crystal Ball function. (Of course, the same reasoning would permit the use of a simple Gaussian function for $^{60}$Co as well. The authors of AdScaled nonetheless chose the more complicated function in production, even though they found a simple Gaussian function to work well during testing.) Once both peaks have been fit, the ratio in question is simply the ratio of the two peaks as defined by the best fits.}, as determined by the nearest long AmC run, and this scaled light yield is stored in the database for use by the reconstruction. This method works because the \emph{ratio} of the nGd and $^{60}$Co peaks is quite stable, even when the peaks themselves are varying. (Omitting $^{60}$Co, and using AmC alone, would avoid the need for this scaling, but the rate of neutrons from the AmC source is insufficient to provide the necessary statistics.) It is worth noting that the resulting energy scale is defined in terms of events at the \emph{center} of the AD, rather than uniformly distributed throughout the GdLS (as in AdSimple). This leads to a consistent $\sim$5\% difference in the energy scale calibration constants between the two algorithms. Essentially, this is only a difference in conventions (i.e., defining the energy scale based on uniformly distributed vs. centered events), which is accounted for at the event-by-event level by the nonuniformity correction, as discussed in \autoref{sec:reconEnergyNU}.

\begin{comment}
  A sample enriched in such neutrons is obtained by selecting events in a time window (XXX define) immediately after AD muons (XXX of what minimum energy?). These captures are distributed uniformly throughout the GdLS, much like IBDs. The nGd capture peak in the charge distribution is fit to a Gaussian (XXX crystal ball?), and the location of the peak is defined as corresponding to 7.95 MeV (XXX) 8.0 MeV according to doc-7334 (AdSimple). This energy scale is stored in the offline database, valid for the period in which the neutrons were collected. In the near (far) halls, it takes XXX (YYY) days to obtain the necessary statistics; this is thus the time-resolution of the energy scale, which is sufficient, given that the light yield changes very slowly, declining by some 1\% to 1.5\% per year.
  
24 hours
\end{comment}

\begin{comment}
  Figure out exactly what energy is pegged by AdSimple and AdScaled. 7.95 MeV? Discuss differences (e.g. due to muon afterpulsing?)
  5x15min Co60
  4x10hour AmC
\end{comment}

\subsubsection{AdSimple calibration procedure}
\label{sec:reconEnergyAdSimpleCalib}

The AdSimple energy calibration begins with the selection of a sample of spallation neutron candidates. These are defined based on their proximity in time to a preceding AD muon, where an AD muon is regarded as any event that produces more than 3,000 photoelectrons of nominal charge. Non-muon events are filtered through a simplified cut to remove instrumental backgrounds (``flashers''); specifically, the \emph{ellipse cut} described in \autoref{sec:bkgFlashers} is employed (\autoref{eq:ellipseCut}). For any surviving event with a nominal charge of more than 100 PE (roughly 0.6~MeV), the charge (after correcting for any dead PMTs or high-voltage channels, as described in \autoref{sec:reconActiveChan}) is added either to a \emph{signal} histogram, if the time since the previous muon is between 20 and \SI{1000}{\micro s}, or to a \emph{background} histogram if $\Delta t$ is between 1020 and \SI{2000}{\micro s}\footnote{The \SI{20}{\micro s} gap between the two windows ensures that both windows are of the same length. Alternatively, a background window of 1000 to \SI{1980}{\micro s} could have been used, etc.}. Given that the characteristic nGd capture time is $\sim$\SI{30}{\micro s}, the latter histogram provides a clean sideband measurement of the background spectrum.

\begin{comment}
  Note: For AdSimpleNL, in reconstruction, a (AD-specific?) scale constant is applied to the non-NL energy scale constant. See line 209 of QsumEnergyTool.cc. Discuss this?
\end{comment}

These histograms are stored in files that correspond one-to-one with Daya Bay DAQ files (each spanning roughly ten minutes in one hall). The files are processed sequentially, and for each AD, a new energy scale constant is calculated once 10,000 entries have been accumulated in the background\footnote{From the sideband.}-subtracted histogram of spallation neutron charges. The constant is determined by fitting the charge spectrum to a double CB function, whose two components, as discussed previously, correspond to the peaks from neutron capture on $^{155}$Gd and $^{157}$Gd. The relationship between the two CB functions (``peaks'') is constrained as follows:

\begin{enumerate}
\item The shape parameters $\alpha$ and $n$ are the same, and constrained to lie within (0, 5) and (0, 1), respectively.
\item The amplitude of the $^{155}$Gd peak is constrained to be 0.227 of the $^{157}$Gd amplitude, according to the product of the relative abundances (14.80\% and 15.65\%, respectively) and neutron capture cross sections (60,700 and 257,000 barns, respectively \cite{doi:10.13182/NSE05-64}) of the two isotopes.
\item The location of the $^{155}$Gd peak is constrained to be 1.0755 of that of the $^{157}$Gd peak, based on the total gamma-ray energies of 8.536 and 7.937~MeV emitted after neutron capture on the two isotopes.
\item The two $\sigma$ (width) parameters are related by the square root of the aforementioned ratio of peak locations.
\end{enumerate}

After the fit is performed (as illustrated in \autoref{fig:escale_fit}), the location parameter $\mu$ of the first peak (generally between 1200 and 1350~PE) is assumed to correspond to 7.937~MeV (from $^{157}$Gd), and so, in this convention, the energy scale constant is simply $\mu/7.937$ PE/MeV. However, due to the PMT afterpulsing that occurs after a high-energy muon event, this value is biased upward compared to the energy scale for the IBD nGd captures. This would not be an issue if the bias were the same size in all halls (since it could then simply be absorbed into a common nonlinearity correction), but because the muon rate and spectrum differ between the halls, so does this bias. Such a systematic difference in energy scales could bias the oscillation fit. Accordingly, the energy scales are corrected by an AD-specific factor (\autoref{tab:ibdSpallCorrs}), empirically determined in order to match the IBD-nGd energy scale in the extrapolated limit of zero muon energy \cite{spallScaleCorr}. These corrected energy scales are stored in the database for use by the AdSimple reconstruction. In \autoref{fig:energy_scales} we plot the energy scale for each AD as a function of time.

\begin{figure}[ht]
  \includegraphics[width=0.65\textwidth]{Reconstruction/escale_fit.pdf}
  \caption{Example of a fit used for determining the AdSimple energy scale.}
  \label{fig:escale_fit}
\end{figure}

\begin{table}[ht]
  \begin{tabular}{lc}
    \toprule
    AD & Correction \\
    \midrule
    EH1-AD1 & 0.9927 \\
    EH1-AD2 & 0.9934 \\
    EH2-AD1 & 0.9921 \\
    EH2-AD2 & 0.9922 \\
    EH3-AD1 & 0.9901 \\
    EH3-AD2 & 0.9904 \\
    EH3-AD3 & 0.9899 \\
    EH3-AD4 & 0.9895 \\
    \bottomrule
  \end{tabular}
  \caption{Correction factors ($E_{\mathrm{IBD}}/E_{\mathrm{spall}}$) relating the energies of n-Gd captures from IBDs to those from spallation neutrons \cite{spallScaleCorr}.}
  \label{tab:ibdSpallCorrs}
\end{table}

\begin{figure}[ht]
  \includegraphics[width=0.65\textwidth]{Reconstruction/energy_scale.pdf}
  \caption{AdSimple energy scale in each AD as a function of time. Deviations from the trend (most notable in EH1-AD2) were caused by application of the incorrect HV (see \autoref{fig:gainDrift}); although the effects of this were canceled to first-order by the gain calibration, some channels with low gain were often unable to exceed the threshold of the discriminator, leading to an effective decrease in the energy scale. This decrease had no significant detrimental impact on the energy reconstruction.}
  \label{fig:energy_scales}
\end{figure}

\subsection{Nonuniformity correction}
\label{sec:reconEnergyNU}

Given the nominal charge $Q$ and the energy scale $S$, we define the \emph{raw visible energy} $\Eraw$ as simply $Q/S$. By construction, $\Eraw$ is anchored to zero and to 7.937~MeV (for n-Gd captures uniformly distributed in the GdLS). At other energies, $\Eraw$ is biased due to the nonlinearity of the scintillator and electronics. The correction for this nonlinearity is discussed in \autoref{sec:reconEnergyNL}. However, since the light collection efficiency varies as a function of position within the AD, we must first correct for this geometric \emph{nonuniformity}. Otherwise, the energy resolution would be degraded. Fortunately, this nonuniformity can be measured and corrected for.

In the case of AdSimple, the current nonuniformity map was produced from three years of data by dividing the AD into pixels (10 in $R^2$ $\times$ 10 in $Z$) and selecting spallation neutron captures on both gadolinium and hydrogen within each pixel. For each pixel $i$ within the GdLS, the nGd spectra was fit to a double Crystal Ball function (along with an additional exponential tail to improve fit quality), and the location of the peak was divided by the mean nGd peak among all $N^{\mathrm{GdLS}}$ GdLS pixels, giving the correction factor $f^{\mathrm{GdLS}}_i$:
\begin{equation}
  \begin{aligned}
    \widebar E_{\mathrm{raw}}^{\mathrm{nGd}} &= \frac{1}{N^{\mathrm{GdLS}}} \sum_i^{\mathrm{GdLS}} E^{\mathrm{nGd}}_{\mathrm{raw},i} \\
    f^{\mathrm{GdLS}}_i &= \frac{E_{\mathrm{raw},i}^{\mathrm{nGd}}}{\widebar E^{\mathrm{nGd}}}
  \end{aligned}
\end{equation}
(This choice of denominator reflects the fact that the energy scale is determined using events uniformly distributed within the GdLS). Meanwhile, for each LS pixel, the nH peak was fit to the ``Daya Bay Function'' (a specific case of the general \emph{Calorimeter Function} developed by members of the collaboration \cite{dybfunction}):
\begin{equation}
  \label{eq:dybfunction}
  \begin{aligned}
    f_{\mathrm{DYB}}(E) = \; & N_\mathrm{peak} \cdot \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(E-\mu)^2}{2\sigma^2}} \\
    & + N_{\mathrm{tail}} \cdot \left\{ \frac{\lambda}{2} e^{\frac{\sigma^2\lambda^2}{2}}
    e^{\lambda E} \left[ \erf\left( \frac{\mu-(E+\sigma^2\lambda)}{\sqrt{2}\sigma} \right) - \erf \left( \frac{0 - (E+\sigma^2\lambda)}{\sqrt{2}\sigma} \right) \right] \right.\\
    & \phantom{ + N_{\mathrm{tail}} \cdot } \left. \quad+\frac{a}{2} \left[ \erf\left( \frac{\mu-E}{\sigma\sqrt{2}} \right)  - \erf \left( \frac{0-E}{\sigma\sqrt{2}} \right)\right]\right \},
  \end{aligned}
\end{equation}
where $E \equiv E_{\mathrm{raw}}$. This function has six parameters: The normalizations $N_{\mathrm{peak}}$ and $N_{\mathrm{tail}}$, the peak location $\mu$, the peak width $\sigma$, and the two tail shape parameters $\lambda$ and $a$. For a given pixel $i$, the fitted peak $\mu$ was divided by the mean nH peak among all \emph{GdLS} pixels
% \footnote{Since the energy scale was determined using GdLS events (spallation nGd captures), the GdLS region is used for the denominator in the correction factor, even though this nH-derived correction is applied \emph{outside} the GdLS.}
\cite[p. 20]{yuryNonUni} to obtain the pixel's nonuniformity factor:
\begin{equation}
  \begin{aligned}
    \widebar E_{\mathrm{raw}}^{\mathrm{nH}} &= \frac{1}{N^{\mathrm{GdLS}}} \sum_i^{\mathrm{GdLS}} E^{\mathrm{nH}}_{\mathrm{raw},i} \\
    f^{\mathrm{LS}}_i &= \frac{E^{\mathrm{nH}}_{\mathrm{raw},i}}{\widebar E_{\mathrm{raw}}^{\mathrm{nH}}}
  \end{aligned}
\end{equation}

Although it may seem strange that the GdLS-wide average is used for the nH-based correction (which only gets applied in the LS), this choice is in fact essential to the validity of the correction. As was discussed earlier, spallation neutron nGd captures are used for defining the AdSimple energy scale, and these events occur only in the GdLS (where their distribution is essentially uniform). Since each pixel's correction factor represents a correction to the energy scale for events inside that pixel, the pixel must be compared to the region used for defining the energy scale, that is, the GdLS.

Each pixel is finally assigned its correction factor based on whether it lies in the GdLS or the LS. For those pixels that contain the boundary of the IAV, the average of the two factors is used:
\begin{equation}
  f_i =
  \begin{cases}
    f^{\mathrm{GdLS}}_i, & \text{inside IAV,} \\
    f^{\mathrm{LS}}_i, & \text{outside IAV,} \\
    (f^{\mathrm{GdLS}} + f^{\mathrm{LS}})/2, & \text{IAV boundary.}
  \end{cases}
\end{equation}
$E_{\mathrm{cor}}$ is then obtained by applying the correction factor:
\begin{equation}
  E_{\mathrm{cor}} = f \cdot E_{\mathrm{raw}},
\end{equation}
where $f$ is calculated by performing bilinear interpolation between the four values of $f_i$ located nearest to the reconstructed position of the event (\autoref{chap:reconVertex}).

An additional complication is the fact that the nonuniformity of the AD changes over time (along with the energy scale), presumably because decreases in the attenuation length of the scintillator will disproportionately affect events located near the edge of the AD, compared with events near the center. This behavior was found to be consistent between all ADs, and adequately captured by the simple analytical expression \cite[p. 16]{yuryNonUni2}:
\begin{equation}
  \frac{\Delta E_{\mathrm{cor}}}{E_{\mathrm{cor},t_0}} = (a + b R^2)\, (t - t_0),
\end{equation}
where $R$ is the radial coordinate (in meters) of the event, $t$ is the time of the event (in units of years, relative to an atbitrary reference point), $t_0$ is the (livetime--weighted) average time for the dataset used in constructing the static nonuniformity corrections $f_i$, and
\begin{align*}
  a &= -0.00149 \pm 0.00030,\\
  b &= 0.00109 \pm 0.00013,
\end{align*}
Computing the final reconstructed energy $E_{\mathrm{rec}}$ from $E_{\mathrm{cor}}$ then involves simply undoing this energy shift:
\begin{equation}
  E_{\mathrm{rec}} = \left[ 1 - (a + b R^2) (t - t_0) \right] \cdot E_{\mathrm{cor}}
\end{equation}
After applying the full (static $\times$ time-dependent) nonuniformity correction, the resulting reconstructed energy $\Erec$ was stored in the processed data file for use in analysis.

\subsection{Nonlinearity correction}
\label{sec:reconEnergyNL}

Ideally, $E_{\mathrm{rec}}$ would be directly proportional to the true deposited energy, across all energies. Unfortunately, this is not the case, due to nonlinear effects produced both by the scintillator and by the electronics.

Within the scintillator, there are two primary sources of nonlinearity: \emph{quenching} \cite{Birks_1951} and \emph{Cherenkov radiation} \cite{cerenkov}. Quenching occurs when the local ionization density is high, allowing fluorescently excited molecules to be ``quenched'' by excited neighbors, preventing light emission. Ionization density is highest when a particle is moving slowly (especially when it is near the end of its range), so, for a low-energy particle, a greater fraction of light will be quenched in comparison to a higher-energy particle, leading to nonlinear light emission as a function of energy.

Meanwhile, the production of Cherenkov light is a complicated and nonlinear function of a particle's initial energy; below the \emph{Cherenkov threshold} $E_{\mathrm{thr}}$, there is no Cherenkov emission at all. The Cherenkov threshold is the energy at which a particle's velocity $\beta_{\mathrm{thr}} c$ is equal to the speed of light in the scintillator, $c/n$:
\begin{equation}
  E_{\mathrm{thr}} = \gamma_{\mathrm{thr}} m = \frac{1}{\sqrt{1 - \beta^2_{\mathrm{thr}}}} m = \frac{1}{\sqrt{1 - n^{-2}}} m
\end{equation}
The Daya Bay scintillator has an index of refraction of approximately 1.5 \cite{Band:2012dh}, giving, for positrons, a threshold of 0.7~MeV; adding the additional $\sim$0.5~MeV from the annihilated electron, this implies that Cherenkov light becomes relevant for reconstructed energies above $\sim$ 1.2~MeV, i.e., the vast majority of the IBD positron spectrum.

As for the electronics, the nonlinearity arises largely from the fact that only the \emph{first} hit is used from each PMT in the charge calculation, leading to the potential exclusion of delayed light from the scintillator. All three of these effects (quenching, Cherenkov emission, and electronics nonlinearity) are detailed in \autoref{sec:reconEnergyNLDetails}. Here we simply present the total nonlinearity model used in this analysis, as illustrated in \autoref{fig:reconPositronNominal}. For each IBD event, this curve is used to convert the prompt reconstructed energy into the corresponding antineutrino energy during the oscillation fit (see \autoref{fig:fitExtrapCartoonOverview} and \autoref{sec:fitNearToFarPred}).

\begin{figure}[h]
  \includegraphics[scale=0.5]{Reconstruction/s06_PositronNominal.pdf}
  \caption{Best-fit nonlinearity model for positrons. From \cite{NonlinearityPaper}.}
  \label{fig:reconPositronNominal}
\end{figure}

\end{document}