\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Reactor prediction}
\label{chap:reactor}


In principle, a reactor-based near/far experiment can measure the oscillation
parameters without any recourse to reactor physics: Simply measure the spectrum
at the near site, ``unoscillate'' it back to the reactor, and then oscillate it
out to the far site. The oscillation parameters are then those that give the
best fit to the far-site data. No information is needed on reactor power,
fission fractions, or theoretical antineutrino spectra.

In practice, the situation is complicated by the fact that Daya Bay features two
reactor complexes and two near sites. Instead of two baselines, there are
effectively six, and the reactors can differ from each other in terms of power
and burnup. These factors must be accounted for when predicting the far site
spectra from the near ones.

In the simplest approach, one can just use the known power and baseline
information to split each near spectrum into components from each reactor, and
then unoscillate/oscillate each component separately to the far site. This can
be done separately for each near site, and the two far site predictions can then
be averaged. This is sufficient for getting a good measurement of $\theta_{13}$,
thanks to the cancellation of absolute efficiency uncertainties and the lack of
need for reactor modeling.

However, measuring $\Delta m^2$ involves examining the detailed shapes of the
near and far spectra. In the simple approach just described, it is assumed that
all reactors are producing the same spectral shape (and ratio of flux to
power). This is not necessarily accurate, as the reactors may be in different
stages of their fuel cycles. Therefore, to get the most out of a rate/shape
analysis, we must perform a full prediction of the spectrum from each reactor
separately. This will, naturally, introduce uncertainties from the imperfect
nature of the predictions. As long as the predictions are applied consistently,
their uncertainties will be largely (but not completely) cancelled in the
near/far ratios, so this primary benefit of a near/far measurement is not lost.

This chapter describes the reactor prediction, beginning with the question of
predicting the antineutrino spectrum from a single fission of a given isotope,
and then proceeding to discuss how these are combined, with the aid of
information on power and burnup (i.e., fission fractions), to form a full
spectrum prediction.

\section{Spectrum prediction}
\label{sec:specpred}

\def\urfive{$^{235}$U\xspace} \def\punine{$^{239}$Pu\xspace}
\def\puone{$^{241}$Pu\xspace} \def\ureight{$^{238}$U\xspace}

In a conventional nuclear reactor, virtually all of the power originates from
the fission of four isotopes: \urfive, \punine, \puone, and \ureight. In a fresh
fuel assembly of low-enriched uranium, initially some 92\% of fissions will be
of \urfive, while the remaining 8\% will be fast-neutron fissions of
\ureight. This \ureight fraction remains nearly constant throughout a fuel
cycle. At the same time, some of the \ureight will undergo neutron capture and
subsequent beta decay to \punine, whose fission rate rapidly reaches 10-20\% of
the total, eventually catching up to the (decreasing) \urfive rate by the end of
the cycle ($\sim$450 days). A fraction of \punine will produce \puone after a
pair of neutron captures, and by the end of the cycle this isotope will
contribute a fission fraction comparable to that of \ureight.

Clearly, all four isotopes contribute a non-neglible fraction of the total
thermal power, and since their antineutrino spectra are fairly similar, they all
contribute significantly to the flux. Therefore, it is imperative that each
isotope's spectrum be predicted as accurately as possible. This can be done
either \emph{ab initio}, by summing theoretical spectra based on the individual
beta branches of all fission products listed in nuclear databases, or via the
\emph{conversion method}, in which the total beta spectrum is measured and then
converted into an antineutrino spectrum. The latter method is generally
preferred when measurements are available, as nuclear databases are known to be
incomplete. In what follows, we discuss the existing predictions produced using
both methods, and determine an optimal set to use in the oscillation analysis.

\subsection{\textit{Ab initio} method}
\label{sec:abinitio}

In a beta decay, conservation of energy implies a one-to-one correspondence
between electron and antineutrino energy.\footnote{Ignoring nuclear recoil
  effects, which introduce a negligible smearing of
  $\mathcal{O}(E_0/(Am_p))\,\sim\,10^{-4}$ [Huber]} For a single beta branch of
endpoint energy $E_0$,

\[ E_\nu = E_0 - E_e. \]

Hence, if we know the spectrum of every beta branch of every fission product, we
can invert them all and sum them up to derive the total antineutrino
spectrum. Unfortunately, this procedure is hampered by two significant
issues. First of all, nuclear databases contain the beta decay \emph{endpoints},
not the spectra, and there are theoretical uncertainties involved in calculating
the spectra. Secondly, existing databases are known to be missing some 10\% of
beta branches, and errors exist in the listed branching ratios for the known
branches.

The theoretical difficulties arise because, to properly model the spectrum for a
single beta branch, it is not enough to merely know the endpoint energy. One
must also know the \emph{type} of decay: Is it a Fermi decay, with antiparallel
electron and antineutrino spins? Or a Gamow-Teller (GT) decay, with parallel
spins? Does the lepton system carry any orbital angular momentum, making it a
\emph{forbidden} (as opposed to an \emph{allowed}) decay? If the decay is
forbidden, does the nucleus undergo the maximum possible $\Delta J$ (a
\emph{unique} decay), or not (a \emph{non-unique} decay)? The type of decay
directly affects the shape of the spectrum.

Traditionally, \emph{ab initio} calculations have assumed that all beta branches
are of allowed GT type. Unfortunately, nuclear databases indicate that some
$\sim$25\% of fission product beta branches are forbidden. Even if we generously
assume that the databases correctly list the type of each decay, there remains a
problem: While it is possible to calculate a general shape correction for
\emph{unique} forbidden decays, the correction for a \emph{non-unique} decay
depends on the exact combination of nuclear matrix elements involved in the
decay, and this information is largely unknown.

Furthermore, the idealized Fermi model of beta decay ignores a number of subtle
effects that add further corrections to the spectrum. Most of these are
well-understood, including the effects of the finite size of the nucleus, charge
screening, and radiative corrections. These corrections can be applied with
minimal uncertainty. However, there is an additional effect known as \emph{weak
  magnetism} (WM): Essentially, the total weak current of the nucleus contains a
contribution from the spatial distribution of the vector current, and this
factor depends on the specific (and typically unknown) details of each nucleus's
structure. In \emph{ab initio} calculations, numerous assumptions and
simplifications are applied in order to produce a tractable model for the WM
correction, which is then fit to measured observables. While this approach is
better than nothing, it still results in one of the largest components of the
uncertainty produced by the \emph{ab initio} method.

Finally, \emph{ab initio} calculations are hampered by the fact that nuclear
databases suffer from missing and incorrect information. This problem is
particularly acute for the rarest and/or most unstable isotopes, some of which
are entirely missing from the databases. Due to their short livetime, these
isotopes are expected to possess high-energy beta branches, well above the
inverse beta decay threshold. Among known daughter isotopes, $\sim$6\% lack
\emph{any} tabulated data on beta branches [Dwyer-Langford]. In [Mueller],
discussed later, their hybrid \emph{ab initio}/conversion procedure suggests
that nuclear databases fail to account for some 10\% of the measured beta decay
spectrum. Even among isotopes for which data exists, this data may be biased by
the \emph{pandemonium effect}, in which low-$E_0$ beta branches are undercounted
relative to high-$E_0$ ones for the same isotope, due to the fact that the
deexcitation of the daughter nucleus involves low-energy transitions between
closely spaced energy levels, and these gammas often evade measurement.

Altogether, while the \emph{ab initio} method is attractive and elegant in
principle, in practice it suffers from deficiencies in underlying nuclear
databases, as well as a poor understanding of the weak magnetism effect. For
this reason it has traditionally been rejected in favor of the conversion
method, described next. The exception is \ureight: Since it is only fissioned by
fast neutrons, measuring the total beta spectrum of its fission daughters is
difficult, and data only became available in the last few years. Given that
\ureight only contributes some 10\% of the total fission rate, even a
conservative 10\% error on the \emph{ab initio} result will only result in an
uncertainty of 1\% on the total spectrum, which is acceptable.

\subsubsection{\ureight calculations}
\label{sec:vogel}

In the 1980s, P.~Vogel carried out a prediction of the \ureight antineutrino
spectrum using the nuclear data available at the time. Although this was a very
careful analysis, certain approximations were made in order to keep the
calculation tractable; for instance, the finite size and weak magnetism effects
were parameterized by a single energy-dependent correction applied to the
spectrum as a whole, rather than being treated branch-by-branch.

In 2011, the ``French'' collaboration of Mueller \emph{et al.} revisited the
problem using the latest available nuclear data, aggregated and curated from
multiple sources. This time, all higher-order corrections were applied on each
branch individually. With these two improvements, along with an increase in the
theoretical IBD cross section, a 9.8\% increase was found in the predicted
\ureight contribution to IBD rate, relative to Vogel's result. To this day, the
French spectrum remains the state-of-the-art among \ureight \emph{ab initio}
predictions, and will be used in this oscillation analysis.

\subsection{Conversion method}
\label{sec:conversion}

In contrast to the \emph{ab initio} method, which depends on thousands of
measurements of individual fission daughters and beta branches, the conversion
procedure relies on just one measurement: The total beta spectrum from fissions
of a given isotope. The total beta spectrum provides a powerful constraint, but
it cannot be directly converted to an antineutrino spectrum the way that a
single branch can. The traditional solution to this problem is to fit the total
spectrum with a series of fictional \emph{virtual} branches, which are then
inverted separately and summed to give the total antineutrino
prediction. Typically, one starts at the endpoint of the total spectrum,
positing a virtual branch (an allowed GT decay, generally) of the same
endpoint. This virtual branch is normalized by fitting it to the end of the
total spectrum, and then subtracted out. The procedure is repeated at the new
endpoint of the subtracted total spectrum, until one finally ends up with a few
dozen virtual branches that together fit the entire spectrum.

While this approach avoids the uncertainties caused by the incompleteness of
nuclear databases, it gains uncertainty from the arbitrary nature of the virtual
branch technique. Fortunately, this uncertainty can be characterized fairly well
by varying the procedure and observing the changes in the result. It should be
noted that, in spite of their relative independence, both approaches suffer from
some of the same theoretical uncertainties involved in inverting single beta
branches (whether real or virtual), particularly from weak magnetism. In the
end, however, the total uncertainty of the conversion approach is found to be
less than that of the \emph{ab initio} approach [XXX by how much?].

\subsubsection{ILL $\beta$ spectra measurements}
\label{sec:illmeas}

For \urfive, \punine, and \puone, all conversion predictions make use of the
same measurements of the total beta spectra. These were taken at ILL in 1980s by
Schrekenbach \emph{et al.}. Thin foils of each isotope were subjected to a
thermal neutron flux from the ILL research reactor, and a small, extremely pure
sample of beta decay electrons escaped through a narrow vacuum pipe for
measurement by a high-resolution magnetic spectrometer, BILL. For normalization,
the total number of fissions was later measured by performing gamma counting on
the foils [XXX check]. These measurements remain the most precise total spectra
in the literature.

\subsubsection{Schreckenbach ILL conversion}
\label{sec:schreck}

After these beta spectra were measured, Schreckenbach \emph{et al.} proceeded to
convert them into antineutrino spectra. Their method was a ``pure'' conversion,
based only on virtual branches with no input from nuclear databases. As with
Vogel's \ureight \emph{ab initio} prediction, certain corrections (finite size,
weak magnetism) were applied in a simplified manner [XXX check] to the total
spectrum, providing the dominant uncertainty on the final result. Until 2011,
the Schreckenbach conversion was considered canonical.

\subsubsection{French ILL conversion}
\label{sec:frenchconv}

The situation changed in 2011 with the work of Mueller \emph{et al.}. The French
team took the attitude that, while nuclear databases are indeed somewhat
incomplete, the data they \emph{do} include is still a precious constraint that
deserves to be considered in the conversion procedure. Accordingly, they began
with an \emph{ab initio} calculation for all four isotopes. For \ureight, as
described above, they had to stop at that point. But for the other three
isotopes, they proceeded to subtract the \emph{ab initio} spectra (for the
electron, not the antineutrino) from the ILL measurements, leaving a $\sim$10\%
residual, which was then fit with virtual branches. This ``hybrid'' approach, by
making use of \emph{all} available data, with its redundant constraints,
resulted in a substantially reduced uncertainty [XXX how much?]. As was
mentioned, Mueller \emph{et al.} also applied a more accurate, branch-by-branch
correction for weak magnetism and other higher-order effects. Their final result
predicted a 3\% total increase in the IBD rate relative to the
Schreckenbach/Vogel predictions.

\subsubsection{Huber ILL conversion}
\label{sec:huberconv}

Shortly after the publication of the French prediction, P.~Huber undertook an
independent calculation of the antinuetrino spectra from \urfive, \punine, and
\puone. Unlike Mueller \emph{et al.}, he avoided using nuclear databases,
instead converting each spectrum using only virtual beta branches, as
Schrekenbach had. His analysis included careful studies of the variance
introduced by the details of the conversion procedure; based on these studies,
the procedure was tuned to minimize any introduced bias [XXX check???]. Like the
French team, Huber carefully treated the WM and other corrections on each
individual virtual branch. With these improvements, Huber obtained a result that
was largely consistent with the French one. In this oscillation analysis, we use
an equally-weighted average of the Huber and Mueller predictions for these three
isotopes [XXX or do we? and how are uncertainties combined?].

\subsubsection{FRM II U238 measurement and conversion}
\label{sec:u238conv}

It is worth noting that in 2013, the \ureight total beta spectrum was finally
measured by N.~Haag \emph{et al.} at the FRM~II neutron source in Germany. They
exposed foils of natural uranium to both thermal and fast neutrons, measuring
the beta spectra with a gamma-suppressing electron telescope, whose efficiency
was accurately determined by comparing their \urfive data to the results from
ILL. This is an extremely valuable measurement, but conversion results remain
preliminary [XXX are they even published?], so for this oscillation analysis we
will instead employ the pure \emph{ab initio} result of Mueller \emph{et al.}

\subsection{Off-equilibrium correction}
\label{sec:offeqcorr}

When a reactor is at equilibrium, each unstable isotope is held at a constant
concentration (modulo evolution of the fuel fractions), decaying at the same
rate as it is generated from its parent. At reactor startup, these
concentrations are all effectively zero, and each isotope accumulates until its
total decay rate equals its production rate. The longer an isotope's lifetime
(or those of its ancestors), the longer this takes.

At ILL, the target foils were irradiated for about a day. However, reactor fuel
typically lives in the core for more than a year. As such, the ILL beta spectra
do not properly account for isotopes that take more than a day to reach
equilibrium. Around 10\% of fission products meet this criterion, so the effect
cannot be neglected. As longer-lived isotopes are the ones affected, the
spectral distortion is restricted to low energies, up to about 4~MeV. Any
correction must obviously be time-dependent, spanning the range from initial
irradiation up to the end of a fuel cycle.

Mueller \emph{et al.} provide correction factors for \urfive, \punine, and
\puone at five energy values from 2 to 4~MeV, calculated at irradiation times of
100~d, 10$^7$~s ($\sim$115~d), 300~d, and 450~d. The ILL reference spectra
provide an anchor at 36~h (except for \urfive, which was measured at 12~h; a
36~h correction is thus provided for the isotope). These corrections, at 450~d,
are at most 2\% (5\% for \urfive). They also account for another, subdominant
difference between the reactor environment and the ILL apparatus, namely, the
presence of epithermal and fast neutrons, which alter the distribution of
fission products. The reactor simulation code MURE was used to determine the
correction, which was validated against the FISACT code.

In this oscillation analysis, we use Mueller's corrections verbatim,
collectively referring to them as the ``off-equilibrium
correction''. Interpolation in time is performed between the provided points,
and the appropriate value of $t$ is determined from data provided by the power
company (discussed in Sec.~\ref{sec:reacpow}). In the Daya Bay cores, one third
of the fuel is replaced during each refueling, so each core contains three fuel
batches at different levels of burnup. Accordingly, a weighted sum of
off-equilibrium corrections is applied. Conveniently, the batched fueling tends
to wash out the differences between cores as well as the overall time dependence
of the correction.

For our purposes, we assign a 30\% uncertainty to the Mueller correction
factors. The correction increases the predicted flux by some 0.5\%, so the
ensuing uncertainty on the absolute rate is around 0.2\%.

\subsection{Spent nuclear fuel}
\label{sec:snfcorr}

During refueling, spent fuel is added to water-filled storage pools on
site. Long lived fission products in the spent fuel will continue to decay for
some time [XXX how long? Check data files], producing an additional low-energy
antineutrino flux whose spectrum can be calculated from nuclear data, assuming
that the fuel's irradiation history (and time since removal) is known.

As virtually all of the relevant decay activity from a spent fuel batch will
have subsided by one year [XXX check], it is reasonable to only consider the
most recent spent batches at each core. Using public information on irradiation
time and fuel quantity, P.~Jaffke has produced reference spectra for one spent
fuel batch at 1~d, 100~d, and 521~d (326~d) after fuel removal at Daya Bay (Ling
Ao). By combining these spectra with the refueling history of each core, the
spent fuel contribution can be calculated. In total, spent fuel is predicted to
account for around 0.3\% of the IBD rate, with an assigned uncertainty of 100\%.

\section{Power, burnup, and fission fractions}
\label{sec:reacpow}

In order to combine the various ingredients above into a final reactor
prediction, we must know the thermal power of each core, its fission fractions,
and its refueling history. This information is provided by the power company in
a number of forms.

Each core's average daily thermal power is provided as a fraction of the full
nominal power (2895~MW). This information is crucial for calculating fuel
fractions (discussed below), but the Daya Bay detectors often do not manage to
produce a full 24~hours of ``good'' data each day. As such, the collaboration
periodically supplies the power company with a ``good hour'' list, from which
the company produces a livetime-averaged daily power. Combined with the daily
livetime, this provides a normalization for the daily predicted spectrum at each
detector.

The fission fractions of a core can be expressed as a function of
\emph{burnup}. Burnup is defined as the total energy extracted from each unit
mass of fuel, typically given in units of MWd/(megaton uranium). The power
company has performed simulations to determine the fission fractions versus
burnup of each core\footnote{Data is provided for a full fuel cycle; for cycles
  that haven't yet run their course, nominal projections of thermal power are
  used for the ``future'' fractions.}, and this information is provided to the
collaboration in intervals of $\sim$1000~MWd/MTU. The company also provides the
burnup of each core at two-week intervals; using daily thermal power to
interpolate between the provided points, the daily burnup, and hence fission
fractions, can be calculated.

[XXX How do we deal with the fact that each core contains three batches at
different burnups? See Christine's code.]

\section{Final AD spectrum}
\label{sec:adspectra}

Putting it all together, the predicted IBD spectrum at a given detector, from a
single core, is

\begin{samepage}
  \[ S_{\mathrm{ibd}}(E, t) = \frac{N_p(t)}{4\pi L^2} \, \epsilon(E, t) \,
    \sigma(E) \left( \sum_i \left( \frac{W(t) \, f_i(t)}{\sum_i f_i(t) \, e_i}
        S_i(E) \, c_{\mathrm{ne},i}(E, t) \right) + S_{\mathrm{snf}}(E, t)
    \right). \]

  Here, $E$ is the \nubar energy, not the IBD prompt energy; $N_p(t)$ is the
  number of target protons; $L$ is the baseline; $\epsilon(E, t)$ is the
  detection efficiency; $\sigma(E)$ is the IBD cross section; $W(t)$ is the
  thermal power; $f_i(t)$ is the fission fraction of isotope $i$, $e_i$ is its
  energy per fission, $S_i(E)$ is its per-fission spectrum, and
  $c_{\mathrm{ne},i}(E, t)$ is its non-equilibrium correction; and finally,
  $S_\mathrm{snf}(E, t)$ is the spectrum from spent fuel. The full prediction at
  each detector is obtained by adding the contributions from each core.
\end{samepage}

\section{Uncertainties and correlations}
\label{sec:reacunccorr}

To be continued.

\end{document}
