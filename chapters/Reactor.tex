\documentclass[../thesis.tex]{subfiles}

\begin{document}

\chapter{Reactor prediction}
\label{chap:bkg}

In principle, a reactor-based near/far experiment can measure the oscillation parameters without any recourse to reactor physics: Simply measure the spectrum at the near site, ``unoscillate'' it back to the reactor, and then oscillate it out to the far site. The oscillation parameters are then those that give the best fit to the far-site data. No information is needed on reactor power, fuel fractions, or theoretical antineutrino spectra.

In practice, the situation is complicated by the fact that Daya Bay features two reactor complexes and two near sites. Instead of two baselines, there are effectively six, and the reactors can differ from each other in terms of power and burnup. These factors must be accounted for when predicting the far site spectra from the near ones.

In the simplest approach, one can just use the known power and baseline information to split each near spectrum into components from each reactor, and then unoscillate/oscillate each component separately to the far site. This can be done separately for each near site, and the two far site predictions can then be averaged. This is sufficient for getting a good measurement of $\theta_{13}$, thanks to the cancellation of absolute efficiency uncertainties and the lack of need for reactor modeling.

However, measuring $\Delta m^2$ involves examining the detailed shapes of the near and far spectra. In the simple approach just described, it is assumed that all reactors are producing the same spectral shape (and ratio of flux to power). This is not necessarily accurate, as the reactors may be in different stages of their fuel cycles. Therefore, to get the most out of a rate/shape analysis, we must perform a full prediction of the spectrum from each reactor separately. This will, naturally, introduce uncertainties from the imperfect nature of the predictions. As long as the predictions are applied consistently, their uncertainties will be largely (but not completely) cancelled in the near/far ratios, so this primary benefit of a near/far measurement is not lost.

This chapter describes the reactor prediction, beginning with the question of predicting the antineutrino spectrum from a single fission of a given isotope, and then proceeding to discuss how these are combined in the Daya Bay reactors, using information on power and burnup (i.e., fission fractions) to form a full spectrum prediction.

\section{Spectrum prediction}
\label{sec:specpred}

\def\urfive{$^{235}$U\xspace}
\def\punine{$^{239}$Pu\xspace}
\def\puone{$^{241}$Pu\xspace}
\def\ureight{$^{238}$U\xspace}

In a conventional nuclear reactor, virtually all of the power originates from the fission of four isotopes: \urfive, \punine, \puone, and \ureight. In a fresh fuel assembly of low-enriched uranium, initially some 92\% of fissions will be of \urfive, while the remaining 8\% will be fast-neutron fissions of \ureight. This \ureight fraction remains nearly constant throughout a fuel cycle. At the same time, some of the \ureight will undergo neutron capture and subsequent beta decay to \punine, whose fission rate rapidly reaches 10-20\% of the total, eventually catching up to the (decreasing) \urfive rate by the end of the cycle ($\sim$450 days). A fraction of \punine will produce \puone after a pair of neutron captures, and by the end of the cycle this isotope will contribute a fission fraction comparable to that of \ureight.

Clearly, all four isotopes contribute a non-neglible fraction of the total thermal power, and since their antineutrino spectra are fairly similar, they all contribute significantly to the flux. Therefore, it is imperative that each isotope's spectrum be predicted as accurately as possible. This can be done either \emph{ab initio}, by summing theoretical spectra based on the individual beta branches of all fission products listed in nuclear databases, or via the \emph{conversion method}, in which the total beta spectrum is measured and then converted into an antineutrino spectrum. The latter method is generally preferred when measurements are available, as nuclear databases are known to be incomplete. In what follows, we discuss the existing predictions produced using both methods, and determine an optimal set to use in the oscillation analysis.

\subsection{\textit{Ab initio} method}
\label{sec:abinitio}

In a beta decay, conservation of energy implies a one-to-one correspondence between electron and antineutrino energy (ignoring nuclear recoil effects, which introduce a negligible smearing of $\mathcal{O}(E_0/(Am_p))\,\sim\,10^{-4}$ [Huber]). For a single beta branch of endpoint energy $E_0$,

\[ E_\nu = E_0 - E_e. \]

Hence, if we know the spectrum of every beta branch of every fission product, we can invert them all and sum them up to derive the total antineutrino spectrum. Unfortunately, this procedure is hampered by two significant issues. First of all, nuclear databases contain the beta decay \emph{endpoints}, not the spectra, and there are theoretical uncertainties involved in calculating the spectra. Secondly, existing databases are known to be missing some 10\% of beta branches, and errors exist in the listed branching ratios for the known branches.

To properly model the spectrum for a single beta branch, it is not enough to merely know the endpoint energy. One must also know the \emph{type} of decay: Is it a Fermi decay, with antiparallel electron and antineutrino spins? Or a Gamow-Teller (GT) decay, with parallel spins? Does the lepton system carry any orbital angular momentum, making it a \emph{forbidden} (as opposed to an \emph{allowed}) decay? If the decay is forbidden, does the nucleus undergo the maximum possible $\Delta J$ (a \emph{unique} decay), or not (a \emph{non-unique} decay)? The type of decay directly affects the shape of the spectrum.

Traditionally, \emph{ab initio} calculations have assumed that all beta branches are of allowed GT type. Unfortunately, nuclear databases indicate that some $\sim$25\% of fission product beta branches are forbidden. Even if we generously assume that the databases correctly list the type of each decay, there remains a problem: While it is possible to calculate a general shape correction for \emph{unique} forbidden decays, the correction for a \emph{non-unique} decay depends on the exact combination of nuclear matrix elements involved in the decay, and this information is largely nonexistent.

Furthermore, the idealized Fermi model of beta decay ignores a number of subtle effects that add further corrections to the spectrum. Most of these are well-understood, including the effects of the finite size of the nucleus, charge screening, and radiative corrections. These corrections can be applied with minimal uncertainty. However, there is an additional effect known as \emph{weak magnetism} (WM): Essentially, the total weak current of the nucleus contains a contribution from the spatial distribution of the vector current, and this factor depends on the specific (and typically unknown) details of each nucleus's structure. In \emph{ab initio} calculations, numerous assumptions and simplifications are applied in order to produce a tractable model for the WM correction, which is then fit to measured observables. While this approach is better than nothing, it still results in one of the largest components of the uncertainty produced by the \emph{ab initio} method.

Finally, \emph{ab initio} calculations are hampered by the fact that nuclear databases suffer from missing and incorrect information. This problem is particularly acute for the rarest and/or most unstable isotopes, some of which are entirely missing from the databases. Due to their short livetime, these isotopes are expected to possess high-energy beta branches, well above the inverse beta decay threshold. Among known daughter isotopes, $\sim$6\% lack \emph{any} tabulated data on beta branches [Dwyer-Langford]. In [Mueller], discussed later, their hybrid \emph{ab initio}/conversion procedure suggests that nuclear databases fail to account for some 10\% of the measured beta decay spectrum. Even among isotopes for which data exists, this data may be biased by the \emph{pandemonium effect}, in which low-$E_0$ beta branches are undercounted relative to high-$E_0$ ones for the same isotope, due to the fact that the deexcitation of the daughter nucleus involves low-energy transitions between closely spaced energy levels, and these gammas often evade measurement.

Altogether, while the \emph{ab initio} method is attractive and elegant in principle, in practice it suffers from deficiencies in underlying nuclear databases, as well as a poor understanding of the weak magnetism effect. For this reason it has been traditionally been rejected in favor of the conversion method, described next. The exception is \ureight; since it is only fissioned by fast neutrons, measuring the total beta spectrum of its fission daughters is difficult, and data only became available in the last few years. Given that \ureight only contributes some 10\% of the total fission rate, even a conservative 10\% error on the \emph{ab initio} result will only result in an uncertainty of 1\% on the total spectrum, which is acceptable.

\subsubsection{\ureight calculations}
\label{sec:vogel}

In the 1980s, P.~Vogel carried out a prediction of the \ureight antineutrino spectrum using the nuclear data available at the time. Although this was a very careful analysis, certain approximations were made in order to keep the calculation tractable; for instance, the finite size and weak magnetism effects were parameterized by a single energy-dependent correction applied to the spectrum as a whole, rather than being treated branch-by-branch.

In 2011, the ``French'' collaboration of Mueller \emph{et al.} revisited the problem using the latest available nuclear data, aggregated and curated from multiple sources. This time, all higher-order corrections were applied on each branch individually. With these two improvements, along with an increase in the theoretical IBD cross section, a 9.8\% increase was found in the predicted \ureight contribution to IBD rate, compared to Vogel's result. To this day, the French spectrum remains the state-of-the-art among \ureight \emph{ab initio} predictions, and will be used in this oscillation analysis.


\subsection{Conversion method}
\label{sec:conversion}

\subsubsection{ILL $\beta$ spectra measurements}
\label{sec:illmeas}

\subsubsection{Schreckenbach ILL conversion}
\label{sec:schreck}

\subsubsection{French ILL conversion}
\label{sec:frenchconv}

\subsubsection{Huber ILL conversion}
\label{sec:huberconv}

\subsubsection{FRM II U238 measurement and conversion}
\label{sec:u238conv}

\subsection{Off-equilibrium correction}
\label{sec:offeqcorr}

\subsection{Spent nuclear fuel}
\label{sec:snfcorr}

\section{Power, burnup, and isotope fractions}
\label{sec:reacpow}

\section{AD spectrum prediction}
\label{sec:adspectra}

\section{Uncertainties and correlations}
\label{sec:reacunccorr}

\end{document}